{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, SimpleRNN, GRU\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from IPython.display import clear_output\n",
    "import mido\n",
    "import glob, pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "    \n",
    "    #use only an eighth quarter of our dataset\n",
    "    len_notes = len(notes)\n",
    "    ab_notes = len_notes // 8\n",
    "    \n",
    "    notes = notes[0:ab_notes]\n",
    "    \n",
    "    # get amount of pitch names\n",
    "    # n_vocab = len(set(np.ndarray.flatten(np.array(notes))))\n",
    "    unpacked_notes = []\n",
    "    \n",
    "    for item in notes:\n",
    "        unpacked_notes.extend(item)\n",
    "    \n",
    "    n_vocab = len(set(unpacked_notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "    \n",
    "    np.save(\"a\", network_input)\n",
    "    np.save(\"b\", network_output)\n",
    "\n",
    "    return train(model, network_input, network_output)\n",
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 50\n",
    "    \n",
    "    unpacked_notes = []\n",
    "    \n",
    "    for item in notes:\n",
    "        unpacked_notes.extend(item)\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in unpacked_notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for song in notes:\n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            sequence_in = song[i:i + sequence_length]\n",
    "            sequence_out = song[i + sequence_length]\n",
    "            network_input.append([note_to_int[char] for char in sequence_in])\n",
    "            network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    assert len(network_input) == len(network_output), len(network_input)\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    # do not reshape coz this is a normal regression\n",
    "    network_input = np.array(network_input)\n",
    "    # assert network_input.shape == (n_patterns, sequence_length)\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n",
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(GRU(\n",
    "        n_vocab,\n",
    "        return_sequences=False,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2])\n",
    "    ))\n",
    "    #model.add(Dense(n_vocab))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"checkpoints-GRU/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    plot = live_plot()\n",
    "    \n",
    "    callbacks_list = [checkpoint, plot]\n",
    "\n",
    "    history_object = model.fit(network_input, network_output, \n",
    "                               epochs=200, batch_size=64,\n",
    "                               validation_split=0.2,\n",
    "                               callbacks=callbacks_list)\n",
    "    return history_object\n",
    "\n",
    "class live_plot(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.index = 0\n",
    "        self.epochs = []\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        \n",
    "        self.figure = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.epochs.append(self.index)\n",
    "        \n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.index += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.epochs, self.losses, label=\"loss\")\n",
    "        plt.plot(self.epochs, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "        plt.plot(self.epochs, self.acc, label=\"acc\")\n",
    "        plt.plot(self.epochs, self.val_acc, label=\"val_acc\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\thistory_object = train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
