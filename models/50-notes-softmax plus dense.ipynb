{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "from music21 import converter, instrument, note, stream, chord\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from IPython.display import clear_output\n",
    "import mido\n",
    "import glob, pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # get amount of pitch names\n",
    "    # n_vocab = len(set(np.ndarray.flatten(np.array(notes))))\n",
    "    unpacked_notes = []\n",
    "    \n",
    "    for item in notes:\n",
    "        unpacked_notes.extend(item)\n",
    "    \n",
    "    n_vocab = len(set(unpacked_notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "    \n",
    "    np.save(\"a\", network_input)\n",
    "    np.save(\"b\", network_output)\n",
    "\n",
    "    return train(model, network_input, network_output)\n",
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 50\n",
    "    \n",
    "    unpacked_notes = []\n",
    "    \n",
    "    for item in notes:\n",
    "        unpacked_notes.extend(item)\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in unpacked_notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for song in notes:\n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            sequence_in = song[i:i + sequence_length]\n",
    "            sequence_out = song[i + sequence_length]\n",
    "            network_input.append([note_to_int[char] for char in sequence_in])\n",
    "            network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    assert len(network_input) == len(network_output), len(network_input)\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    # do not reshape coz this is a normal regression\n",
    "    network_input = np.array(network_input)\n",
    "    assert network_input.shape == (n_patterns, sequence_length)\n",
    "    # network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n",
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(network_input.shape[1],)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"checkpoints-50-s-d/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    plot = live_plot()\n",
    "    \n",
    "    callbacks_list = [checkpoint, plot]\n",
    "\n",
    "    history_object = model.fit(network_input, network_output, \n",
    "                               epochs=100, batch_size=64,\n",
    "                               validation_split=0.2,\n",
    "                               callbacks=callbacks_list)\n",
    "    return history_object\n",
    "\n",
    "class live_plot(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.index = 0\n",
    "        self.epochs = []\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        \n",
    "        self.figure = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.epochs.append(self.index)\n",
    "        \n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.index += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.epochs, self.losses, label=\"loss\")\n",
    "        plt.plot(self.epochs, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "        plt.plot(self.epochs, self.acc, label=\"acc\")\n",
    "        plt.plot(self.epochs, self.val_acc, label=\"val_acc\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\thistory_object = train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "    \n",
    "    unpacked_notes = []\n",
    "    \n",
    "    for item in notes:\n",
    "        unpacked_notes.extend(item)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in unpacked_notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(unpacked_notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)\n",
    "\n",
    "def prepare_sequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 50\n",
    "    network_input = []\n",
    "    output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for song in notes:\n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            sequence_in = song[i:i + sequence_length]\n",
    "            sequence_out = song[i + sequence_length]\n",
    "            network_input.append([note_to_int[char] for char in sequence_in])\n",
    "            output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    assert len(network_input) == len(output), len(network_input)\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    network_input = np.array(network_input)\n",
    "    assert network_input.shape == (n_patterns, sequence_length)\n",
    "\n",
    "    # normalize input\n",
    "    normalized_input = network_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)\n",
    "\n",
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_vocab, input_shape=(50,)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "    \n",
    "    # Load the weights to each node\n",
    "    model.load_weights('checkpoints-50-s/weights-improvement-81-3.6384-bigger.hdf5')\n",
    "\n",
    "    return model\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start, :]\n",
    "    \n",
    "    assert pattern.shape == (50,), pattern.shape\n",
    "    \n",
    "    #pattern = pattern.reshape((1,50))\n",
    "    \n",
    "    pattern = pattern.tolist()\n",
    "    \n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.array(pattern)\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "        assert prediction_input.shape == (50,), prediction_input.shape\n",
    "        prediction_input = prediction_input.reshape((1,50))\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output_softmax.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
